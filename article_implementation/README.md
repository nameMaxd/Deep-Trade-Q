# Реализация алгоритма TD3 для торговли на фондовом рынке

Эта директория содержит полную реализацию алгоритма TD3 (Twin Delayed Deep Deterministic Policy Gradient) для автоматической торговли на фондовом рынке, как описано в статье "Deep Reinforcement Learning Approach for Trading Automation in The Stock Market".

## Структура проекта

- `environment.py` - Реализация торговой среды как POMDP (Partially Observed Markov Decision Process)
- `td3_agent.py` - Основные классы для TD3 агента (Actor)
- `td3_agent_part2.py` - Дополнительные классы для TD3 агента (Critic, ReplayBuffer)
- `td3_agent_part3.py` - Основной класс TD3Agent
- `td3_agent_part4.py` - Функции для обучения и оценки
- `td3_agent_part5.py` - Функции для оценки и визуализации результатов
- `main.py` - Основной скрипт для запуска обучения и оценки
- `sentiment_analysis.py` - Анализ настроений для финансовых новостей
- `technical_indicators.py` - Расчет технических индикаторов
- `volume_profile.py` - Анализ профиля объема и ликвидности
- `multi_asset_environment_part1.py` - Мультиактивная торговая среда (часть 1)
- `multi_asset_environment_part2.py` - Мультиактивная торговая среда (часть 2)
- `multi_asset_environment_part3.py` - Мультиактивная торговая среда (часть 3)
- `multi_asset_wrapper.py` - Обертка для объединения частей мультиактивной среды

## Как использовать

### Обучение модели

```bash
python main.py --train_data data/GOOG_2010-2024-06.csv --test_data data/GOOG_2024-07_2025-04.csv --window_size 47 --timesteps 100000 --batch_size 256 --exploration_noise 0.1
```

### Оценка модели

```bash
python main.py --train_data data/GOOG_2010-2024-06.csv --test_data data/GOOG_2024-07_2025-04.csv --load_model results/td3_XXXXXXXX_XXXXXX/final_model --eval_only
```

## Параметры командной строки

- `--train_data` - Путь к CSV-файлу с обучающими данными (обязательный)
- `--test_data` - Путь к CSV-файлу с тестовыми данными (опциональный)
- `--window_size` - Размер окна для анализа (по умолчанию 47)
- `--initial_balance` - Начальный баланс (по умолчанию 10000.0)
- `--commission` - Комиссия за сделку (по умолчанию 0.001)
- `--max_inventory` - Максимальное количество позиций (по умолчанию 8)
- `--timesteps` - Общее количество шагов для обучения (по умолчанию 100000)
- `--batch_size` - Размер батча для обучения (по умолчанию 256)
- `--policy_noise` - Шум для политики (по умолчанию 0.2)
- `--noise_clip` - Ограничение шума (по умолчанию 0.5)
- `--exploration_noise` - Шум для исследования (по умолчанию 0.1)
- `--output_dir` - Директория для результатов (по умолчанию 'results')
- `--load_model` - Путь для загрузки модели
- `--eval_only` - Только оценка, без обучения

## Особенности реализации

1. **Торговая среда (POMDP)**:
   - Поддержка торговли несколькими активами
   - Непрерывное пространство действий
   - Реалистичные ограничения (комиссии, минимальный размер сделки и т.д.)
   - Расчет технических индикаторов

2. **TD3 агент**:
   - Twin Delayed архитектура для снижения переоценки Q-значений
   - Шум для сглаживания целевой политики
   - Отложенное обновление политики

3. **Анализ настроений**:
   - Использование FinBERT для анализа финансовых новостей
   - Интеграция настроений в вектор состояния

4. **Профиль объема и ликвидность**:
   - Анализ распределения объема по ценовым уровням
   - Определение уровней поддержки и сопротивления
   - Оценка ликвидности рынка

5. **Мультиактивная торговля**:
   - Поддержка одновременной торговли несколькими активами
   - Оптимизация распределения капитала между активами
   - Учет корреляции между активами

6. **Метрики оценки**:
   - Коэффициент Шарпа
   - Максимальная просадка
   - Доходность
   - Количество сделок

## Требования

- Python 3.8+
- NumPy
- Pandas
- Matplotlib
- PyTorch
- Gymnasium (OpenAI Gym)
- tqdm
- transformers (для анализа настроений)

## Цитирование

Если вы используете этот код в своей работе, пожалуйста, цитируйте оригинальную статью:

```
@article{kabbani2022deep,
  title={Deep Reinforcement Learning Approach for Trading Automation in The Stock Market},
  author={Kabbani, Taylan and Duman, Ekrem},
  journal={arXiv preprint arXiv:2208.07156},
  year={2022}
}
```
